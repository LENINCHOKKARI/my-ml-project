{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚ö° ML Project - Lightning AI GPU Training\n",
    "\n",
    "**Lightning AI provides 22 FREE GPU hours/month with A10G GPU (24GB VRAM)!**\n",
    "\n",
    "**Instructions:**\n",
    "1. Go to: https://lightning.ai\n",
    "2. Create free account\n",
    "3. Create **New Studio** ‚Üí Choose **GPU** instance\n",
    "4. Upload this notebook and run!\n",
    "\n",
    "**Free Tier**: 22 GPU hours/month with powerful A10G GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Clone your project in Lightning AI\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Clone your repository (if not already done)\n",
    "if not os.path.exists('my-ml-project'):\n",
    "    !git clone https://github.com/LENINCHOKKARI/my-ml-project.git\n",
    "    os.chdir('my-ml-project')\n",
    "    print(\"‚úÖ Repository cloned successfully!\")\n",
    "else:\n",
    "    print(\"‚úÖ Repository already exists!\")\n",
    "\n",
    "# Install requirements\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "print(\"‚ö° Lightning AI setup complete!\")\n",
    "print(\"üöÄ Ready for high-performance GPU training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö° Check Lightning AI GPU setup\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import subprocess\n",
    "\n",
    "print(\"‚ö° Lightning AI Environment Check:\")\n",
    "print(f\"üöÄ PyTorch CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üì± GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"üî• CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"üí° GPU not detected. Make sure you selected a GPU instance.\")\n",
    "\n",
    "# Check NVIDIA GPU details\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"\\nüéÆ NVIDIA GPU Info:\")\n",
    "        print(result.stdout)\n",
    "except:\n",
    "    print(\"\\nüí° nvidia-smi not available\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n‚ö° Using device: {device}\")\n",
    "print(f\"üß† PyTorch Lightning version: {pl.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö Import Lightning AI optimized libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch Lightning (optimized for Lightning AI)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# Additional ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "print(\"üìä All libraries imported successfully!\")\n",
    "print(\"‚ö° Ready for Lightning AI GPU training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° PyTorch Lightning Model Example\n",
    "\n",
    "**Lightning AI is PERFECT for PyTorch Lightning!**\n",
    "\n",
    "**Advantages:**\n",
    "- üéØ **A10G GPU** with 24GB VRAM (more than Colab!)\n",
    "- ‚ö° **Built for Lightning** - optimized performance\n",
    "- üî¨ **Research-grade** environment\n",
    "- üíæ **Persistent storage** - save your work\n",
    "- üöÄ **22 hours/month** of powerful GPU time\n",
    "\n",
    "Perfect for serious ML training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö° Lightning Module Example\n",
    "class LightningMLModel(pl.LightningModule):\n",
    "    def __init__(self, input_size=784, hidden_size=256, num_classes=10, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Model architecture\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        acc = torch.sum(preds == y).float() / len(y)\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "print(\"‚ö° Lightning Model defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Prepare data (MNIST example)\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# Data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Download datasets\n",
    "train_dataset = MNIST('data', train=True, download=True, transform=transform)\n",
    "val_dataset = MNIST('data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"üìä Training samples: {len(train_dataset)}\")\n",
    "print(f\"üìä Validation samples: {len(val_dataset)}\")\n",
    "print(\"‚úÖ Data prepared for Lightning AI training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö° Train with Lightning AI GPU power!\n",
    "if torch.cuda.is_available():\n",
    "    print(\"üöÄ Training with Lightning AI A10G GPU!\")\n",
    "    \n",
    "    # Initialize model\n",
    "    model = LightningMLModel()\n",
    "    \n",
    "    # Callbacks\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_acc',\n",
    "        mode='max',\n",
    "        save_top_k=1,\n",
    "        filename='best-model-{epoch:02d}-{val_acc:.2f}'\n",
    "    )\n",
    "    \n",
    "    # Lightning Trainer (optimized for Lightning AI)\n",
    "    trainer = Trainer(\n",
    "        max_epochs=10,\n",
    "        accelerator='gpu',\n",
    "        devices=1,\n",
    "        callbacks=[checkpoint_callback],\n",
    "        log_every_n_steps=50\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    \n",
    "    print(\"‚úÖ Lightning AI GPU training complete!\")\n",
    "    print(f\"üèÜ Best model saved: {checkpoint_callback.best_model_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"üí° GPU not available - make sure you selected GPU instance in Lightning AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ Save and sync results\n",
    "# Your trained models are automatically saved in Lightning AI\n",
    "\n",
    "# Optional: Push results back to GitHub\n",
    "# !git add .\n",
    "# !git commit -m \"Lightning AI training results\"\n",
    "# !git push origin main\n",
    "\n",
    "print(\"üéâ Lightning AI training session complete!\")\n",
    "print(\"‚ö° A10G GPU performance: AMAZING for ML training!\")\n",
    "print(\"üíæ Models saved in Lightning AI workspace\")\n",
    "print(\"üîÑ Sync results back to GitHub when ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Lightning AI Benefits\n",
    "\n",
    "**Free Tier:**\n",
    "- 22 GPU hours/month\n",
    "- A10G GPU (24GB VRAM!)\n",
    "- 4 CPU cores, 16GB RAM\n",
    "- Persistent storage\n",
    "\n",
    "**Perfect for:**\n",
    "- ‚ö° **PyTorch Lightning** development\n",
    "- üî¨ **Research projects** - powerful GPU\n",
    "- üèãÔ∏è **Serious training** - 24GB VRAM\n",
    "- üéØ **Professional ML** workflows\n",
    "\n",
    "**Why Lightning AI Rocks:**\n",
    "- üí™ **Most powerful free GPU** (A10G vs T4)\n",
    "- ‚ö° **Built for Lightning** - optimized performance\n",
    "- üî¨ **Research-grade** environment\n",
    "- üìä **Advanced ML tools** included\n",
    "\n",
    "Lightning AI + PyTorch Lightning = Perfect match! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}